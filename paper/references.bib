@Manual{tidyr,
    title={{tidyr: Tidy Messy Data}},
    author={Hadley Wickham},
    year={2020},
    note={R package version 1.1.2},
    url={https://CRAN.R-project.org/package=tidyr}
  }

@Manual{dplyr,
    title = {{dplyr: A Grammar of Data Manipulation}},
    author = {Hadley Wickham and Romain François and Lionel {
             Henry} and Kirill Müller},
    year = {2020},
    note = {R package version 1.0.2},
    url = {https://CRAN.R-project.org/package=dplyr}
  }

@Manual{stringr,
    title = {{stringr: Simple, Consistent Wrappers for Common String Operations}},
    author = {Hadley Wickham},
    year = {2019},
    note = {R package version 1.4.0},
    url = {https://CRAN.R-project.org/package=stringr}
  }

@article{HuebnerMariannePhD2016Asat,
issn = {0022-5223},
abstract = {Abstract Initial data analysis is conducted independently of the analysis needed to address the research questions. Shortcomings in these first steps may result in inappropriate statistical methods or incorrect conclusions. We outline a framework for initial data analysis and illustrate the impact of initial data analysis on research studies. Examples of reporting of initial data analysis in publications are given. A systematic and careful approach to initial data analysis is needed as good research practice.},
journal = {The Journal of thoracic and cardiovascular surgery},
pages = {25--27},
volume = {151},
publisher = {Elsevier Inc},
number = {1},
year = {2016},
title = {A systematic approach to initial data analysis is good research practice},
copyright = {The American Association for Thoracic Surgery},
language = {eng},
address = {United States},
author = {Huebner, Marianne, and Vach, Werner and le Cessie, Saskia},
keywords = {Cardiothoracic Surgery ; data screening ; data cleaning ; initial data analysis ; Data Collection - statistics & numerical data ; Data Interpretation, Statistical ; Reproducibility of Results ; Humans ; Biomedical Research - statistics & numerical data ; Biomedical Research - methods ; Models, Statistical ; Research Design - statistics & numerical data ; Analysis ; Information management ; Index Medicus ; Abridged Index Medicus},
}

@article{Chatfield1985TIEo,
issn = {0035-9238},
abstract = {The initial examination of data (abbreviated IDA) is a valuable stage of most statistical investigations, not only for scrutinizing and summarizing data, but also for model formulation. Several examples are presented to illustrate the benefits of IDA, particularly that IDA may be all that is necessary or desirable. In particular, a re-analysis of the notorious teaching styles data produces completely different conclusions to earlier studies. A critical comparison is made between IDA and Tukey's exploratory data analysis approach. Some reasons why IDA is often neglected or undervalued are discussed and countered. Some implications for the teaching of Statistics are considered.},
journal = {Journal of the Royal Statistical Society. Series A. General},
pages = {214--253},
volume = {148},
publisher = {Royal Statistical Society},
number = {3},
year = {1985},
title = {The Initial Examination of Data},
copyright = {Copyright 1985 Royal Statistical Society},
language = {eng},
address = {London},
author = {C. Chatfield},
keywords = {Outliers ; Datasets ; Statistical variance ; Data analysis ; Applied statistics ; Inference ; Mathematics education ; Descriptive statistics ; Statistics ; Modeling ; computer packages ; graphical procedures ; exploratory data analysis ; descriptive statistics ; model formulation ; teaching statistics ; outliers ; teaching styles data ; data editing ; significance tests ; errors},
}

@Manual{brolgar,
    title = {{brolgar: BRowse Over Longitudinal data Graphically and Analytically in R}},
    author = {Nicholas Tierney and Di Cook and Tania Prvan},
    year = {2020},
    note = {R package version 0.0.6.9100},
    url = {https://github.com/njtierney/brolgar},
  }

@Book{ggplot2,
    author = {Hadley Wickham},
    title = {{ggplot2: Elegant Graphics for Data Analysis}},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
  }

@article{KollerManuel2016rARP,
issn = {1548-7660},
abstract = {As any real-life data, data modeled by linear mixed-effects models often contain outliers or other contamination. Even little contamination can drive the classic estimates far away from what they would be without the contamination. At the same time, datasets that require mixed-effects modeling are often complex and large. This makes it difficult to spot contamination. Robust estimation methods aim to solve both problems: to provide estimates where contamination has only little influence and to detect and flag contamination. We introduce an R package, robustlmm, to robustly fit linear mixed-effects models. The package's functions and methods are designed to closely equal those offered by lme4, the R package that implements classic linear mixed-effects model estimation in R. The robust estimation method in robustlmm is based on the random effects contamination model and the central contamination model. Contamination can be detected at all levels of the data. The estimation method does not make any assumption on the data's grouping structure except that the model parameters are estimable. robustlmm supports hierarchical and non-hierarchical (e.g., crossed) grouping structures. The robustness of the estimates and their asymptotic efficiency is fully controlled through the function interface. Individual parts (e.g., fixed effects and variance components) can be tuned independently. In this tutorial, we show how to fit robust linear mixed-effects models using robustlmm, how to assess the model fit, how to detect outliers, and how to compare different fits.},
journal = {Journal of statistical software},
pages = {1--24},
volume = {75},
publisher = {Foundation for Open Access Statistics},
number = {6},
year = {2016},
title = {{robustlmm: An R Package for Robust Estimation of Linear Mixed-Effects Models}},
language = {eng},
author = {Koller, Manuel},
keywords = {random effect ; hierarchical model ; mixed-effects model ; crossed ; ANOVA ; robust statistics},
}



@ONLINE{rlm,
  author = {{UCLA: Statistical Consulting Group}},
  title = {{Robust Regression | R Data Analysis Examples}},
  month = FEB,
  year = {2021},
  url = {https://stats.idre.ucla.edu/r/dae/robust-regression/}
}


@Book{mass,
    title = {Modern Applied Statistics with S},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0},
    url = {http://www.stats.ox.ac.uk/pub/MASS4},
  }


@Manual{purrr,
    title = {{purrr: Functional Programming Tools}},
    author = {Lionel Henry and Hadley Wickham},
    year = {2020},
    note = {R package version 0.3.4},
    url = {https://CRAN.R-project.org/package=purrr},
  }


@book{DasuTamraparni2003Edma,
series = {Wiley series in probability and statistics},
abstract = {TAMRAPARNI DASU, PhD, and THEODORE JOHNSON, PhD, are both members of the technical staff at AT&T Labs-Research in Florham Park, New Jersey.},
publisher = {WILEY},
booktitle = {<h>Exploratory data mining and data cleaning</h>},
isbn = {9780471448358},
year = {2003},
title = {Exploratory data mining and data cleaning},
language = {eng},
address = {Hoboken},
author = {Dasu, Tamraparni and Johnson, Theodore},
keywords = {Probability & Statistics ; General ; Mathematics ; Electronic data processing ; Data preparation ; Data mining ; Quality control},
}

@article{WickhamHadley2014TD,
issn = {1548-7660},
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
journal = {Journal of statistical software},
pages = {1--23},
volume = {59},
publisher = {Foundation for Open Access Statistics},
number = {10},
year = {2014},
title = {Tidy Data},
language = {eng},
author = {Wickham, Hadley},
}


@incollection{eliznlsy,
  author       = {Elizabeth C. Cooksey},
  title        = {Using the National Longitudinal Surveys of Youth (NLSY) to Conduct Life Course Analyses},
  booktitle    = {Handbook of Life Course Health Development},
  publisher    = {Springer},
  year         = 2017,
  editor       = {Neal Halfon, Christoper B. Forrest, Richard M. Lerner, Elaine M. Faustman},
  doi          = {https://doi.org/10.1007/978-3-319-47143-3_23},
  pages        = {561-577},
  address      = {Cham},
  month        = 11
}


@article{MichaelRPergamit2001DWTN,
issn = {0895-3309},
abstract = {This article describes the design features and topical coverage of the National Longitudinal Surveys (NLS). The NLS are perhaps the oldest and most widely used panel surveys of individuals in the United States. These surveys were started in the mid-1960s to exam employment issues faced by different cohorts of the U.S. population. Since then, the NLS surveys have expanded to include two new cohorts of youth. Survey topic areas include employment, education, training, family relationships, financial well-being, and health. Information on data access is also provided.},
journal = {The Journal of economic perspectives},
pages = {239--253},
volume = {15},
publisher = {American Economic Association},
number = {2},
year = {2001},
title = {Data Watch: The National Longitudinal Surveys},
copyright = {Copyright 2001 American Economic Association},
language = {eng},
address = {Nashville},
author = {Michael R. Pergamit and Charles R. Pierret and Donna S. Rothstein and Jonathan R. Veum},
keywords = {Job training ; Economic theory ; Employment ; Men ; Economic surveys ; Labor markets ; Spouses ; Longitudinal studies ; Features ; Children ; School surveys ; Employment surveys ; Surveys ; Educational surveys ; United States ; Health ; Family ; Layoffs ; Labor market ; Population ; Labor force ; Employment interviews ; Polls & surveys},
}

@article{HuebnerMarianne2020Haar,
issn = {1471-2288},
abstract = {In the data pipeline from the data collection process to the planned statistical analyses, initial data analysis (IDA) typically takes place between the end of the data collection and do not touch the research questions. A systematic process for IDA and clear reporting of the findings would help to understand the potential shortcomings of a dataset, such as missing values, or subgroups with small sample sizes, or shortcomings in the collection process, and to evaluate the impact of these shortcomings on the research results. A clear reporting of findings is also relevant when making datasets available to other researchers. Initial data analyses can provide valuable insights into the suitability of a data set for a future research study. Our aim was to describe the practice of reporting of initial data analyses in observational studies in five highly ranked medical journals with focus on data cleaning, screening, and reporting of findings which led to a potential change in the analysis plan.
This review was carried out using systematic search strategies with eligibility criteria for articles to be reviewed. A total of 25 papers about observational studies were selected from five medical journals published in 2018. Each paper was reviewed by two reviewers and IDA statements were further discussed by all authors. The consensus was reported.
IDA statements were reported in the methods, results, discussion, and supplement of papers. Ten out of 25 papers (40%) included a statement about data cleaning. Data screening statements were included in all articles, and 18 (72%) indicated the methods used to describe them. Item missingness was reported in 11 papers (44%), unit missingness in 15 papers (60%). Eleven papers (44%) mentioned some changes in the analysis plan. Reported changes referred to missing data treatment, unexpected values, population heterogeneity and aspects related to variable distributions or data properties.
Reporting of initial data analyses were sparse, and statements on IDA were located throughout the research articles. There is a lack of systematic reporting of IDA. We conclude the article with recommendations on how to overcome shortcomings in the practice of IDA reporting in observational studies.},
journal = {BMC medical research methodology},
pages = {61--61},
volume = {20},
publisher = {BioMed Central},
number = {1},
year = {2020},
title = {Hidden analyses: a review of reporting practice and recommendations for more transparent reporting of initial data analyses},
copyright = {2020. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
language = {eng},
address = {England},
author = {Huebner, Marianne and Vach, Werner and le Cessie, Saskia and Schmidt, Carsten Oliver and Lusa, Lara},
keywords = {Variables ; Data collection ; Medical research ; Data analysis ; Journals ; Index Medicus ; Reporting ; Observational studies ; Initial data analysis ; STRATOS initiative},
organization = {Topic Group “Initial Data Analysis” of the STRATOS Initiative (STRengthening Analytical Thinking for Observational Studies, http://www.stratos-initiative.org)},
}


@online{opendata,
  author = {{Open Knowledge Foundation}},
  title = {Open Definition. Defining Open in Open Data, Open Content, and Open Knowledge},
  url = {http://opendefinition.org/od/2.1/en/},
  urldate = {2021-03-03},
  year = {2021}
}


@book{SingerJudithD2003Alda,
abstract = {In this book, [the authors] use concrete examples and careful explanation to demonstrate how research questions about change and event occurrence can be addressed with longitudinal data. In doing so, [they] reveal research opportunities unavailable in the world of cross-sectional data. ... The book is divided into two major parts: individual growth modelling in the first half, survival analysis in the second. Throughout each half, [are stressed] the important connections between the methods. Each half has its own introduction that 1) discusses when the method might be used; 2) distinguishes among the different types of research questions in that domain and 3) identifies the major statistical features of empirical studies that lend themselves to the specified analyses. Both types of analyses require a sensible metric for clocking time. But in growth modelling ... multiple waves of data [are needed] and an outcome that changes systematically whereas in survival analysis, [the reader] must clearly identify the beginning of time and the criteria used to assess event occurrence. Subsequent chapters in each half of the book walk [the reader] through the details of analysis. Each begins with a chapter on data description and exploratory analysis, followed by a detailed discussion of model specification, model fitting, and parameter interpretation. Having introduced a basic model, [the authors] consider extensions. Because it is easier to understand the path that winds through the book only after important issues relevant for each half have been introduced, [they] defer discussion of each half's outline to its associated introductory chapter. (DIPF/Orig.).},
publisher = {Oxford Univ. Pr},
booktitle = {Applied longitudinal data analysis},
isbn = {0195152964},
year = {2003},
title = {Applied longitudinal data analysis: Modeling change and event occurrence},
language = {eng},
address = {Oxford u.a},
author = {Singer, Judith D and Willett, John B},
keywords = {Modellbildung ; Längsschnittuntersuchung ; Beispiel ; Datenanalyse ; Forschungsdesign ; Statistik ; Methodologie ; Geschichte (Histor) ; Epidemiology ; Public Health ; Longitudinal method ; Social sciences ; Research},
}


@book{tukey,
series = {Addison-Wesley series in behavioral science},
publisher = {Addison-Wesley Pub. Co.},
isbn = {0201076160},
year = {1977},
title = {Exploratory data analysis},
language = {eng},
address = {Reading, Mass.},
author = {Tukey, John W. (John Wilder)},
keywords = {Statistics},
}


@Manual{shiny,
    title = {{shiny: Web Application Framework for R}},
    author = {Winston Chang and Joe Cheng and JJ Allaire and Yihui Xie and Jonathan McPherson},
    year = {2020},
    note = {R package version 1.5.0},
    url = {https://CRAN.R-project.org/package=shiny},
  }

@Article{validate,
    title = {Data Validation Infrastructure for {R}},
    author = {Mark P. J. {van der Loo} and Edwin {de Jonge}},
    journal = {Journal of Statistical Software},
    year = {2021},
    volume = {97},
    number = {10},
    pages = {1--31},
    doi = {10.18637/jss.v097.i10},
  }

@Manual{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2020},
    url = {https://www.R-project.org/},
  }

% https://www.nlsinfo.org/bibliography-citing-nls-data
%   = {Available at \url{https://www.nlsinfo.org/content/cohorts/nlsy79} (2021/25/02)}
@misc{nlsy79,
  author = {{Bureau of Labor Statistics, U.S. Department of Labor}},
  title = {National Longitudinal Survey of Youth 1979 cohort, 1979-2016 (rounds 1-28).},
  howpublished = {Produced and distributed by the Center for Human Resource Research (CHRR), The Ohio State University. Columbus, OH},
  year = 2021
  }

@Article{tidyverse,
    title = {Welcome to the {tidyverse}},
    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
    year = {2019},
    journal = {Journal of Open Source Software},
    volume = {4},
    number = {43},
    pages = {1686},
    doi = {10.21105/joss.01686},
  }



@Manual{readr,
    title = {{readr: Read Rectangular Text Data}},
    author = {Hadley Wickham and Jim Hester},
    year = {2020},
    note = {R package version 1.4.0},
    url = {https://CRAN.R-project.org/package=readr},
  }


@Manual{broom,
    title = {{broom: Convert Statistical Objects into Tidy Tibbles}},
    author = {David Robinson and Alex Hayes and Simon Couch},
    year = {2021},
    note = {R package version 0.7.5},
    url = {https://CRAN.R-project.org/package=broom},
  }



@Manual{patchwork,
    title = {{patchwork: The Composer of Plots}},
    author = {Thomas Lin Pedersen},
    year = {2020},
    note = {R package version 1.0.1},
    url = {https://CRAN.R-project.org/package=patchwork},
  }

@Manual{kableExtra,
    title = {{kableExtra: Construct Complex Table with 'kable' and Pipe Syntax}},
    author = {Hao Zhu},
    year = {2019},
    note = {R package version 1.1.0},
    url = {https://CRAN.R-project.org/package=kableExtra},
  }

@Manual{janitor,
    title = {{janitor: Simple Tools for Examining and Cleaning Dirty Data}},
    author = {Sam Firke},
    year = {2020},
    note = {R package version 2.0.1},
    url = {https://CRAN.R-project.org/package=janitor},
  }


@InCollection{knitr,
    booktitle = {Implementing Reproducible Computational Research},
    editor = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
    title = {knitr: A Comprehensive Tool for Reproducible Research in {R}},
    author = {Yihui Xie},
    publisher = {Chapman and Hall/CRC},
    year = {2014},
    note = {ISBN 978-1466561595},
    url = {http://www.crcpress.com/product/isbn/9781466561595},
  }

@Book{rmarkdown,
    title = {R Markdown Cookbook},
    author = {Yihui Xie and Christophe Dervieux and Emily Riederer},
    publisher = {Chapman and Hall/CRC},
    address = {Boca Raton, Florida},
    year = {2020},
    note = {ISBN 9780367563837},
    url = {https://bookdown.org/yihui/rmarkdown-cookbook},
  }


@Article{tsibble,
    author = {Earo Wang and Dianne Cook and Rob J Hyndman},
    title = {A new tidy data structure to support exploration and modeling of temporal data},
    journal = {Journal of Computational and Graphical Statistics},
    volume = {29},
    number = {3},
    pages = {466-478},
    year = {2020},
    publisher = {Taylor & Francis},
    doi = {10.1080/10618600.2019.1695624},
    url = {https://doi.org/10.1080/10618600.2019.1695624},
  }

@misc{OECD,
  author = {{OECD}},
  title = {Gender wage gap},
  howpublished = {https://data.oecd.org/earnwage/gender-wage-gap.htm},
  note = "Accessed 2021/11/08"
}


@Article{lme4,
    title = {Fitting Linear Mixed-Effects Models Using {lme4}},
    author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve Walker},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {67},
    number = {1},
    pages = {1--48},
    doi = {10.18637/jss.v067.i01},
  }

@book{LooMarkvander2018Sdcw,
issn = {9781118897157},
abstract = {A comprehensive guide to automated statistical data cleaning The production of clean data is a complex and time-consuming process that requires both technical know-how and statistical expertise. Statistical Data Cleaning brings together a wide range of techniques for cleaning textual, numeric or categorical data. This book examines technical data cleaning methods relating to data representation and data structure. A prominent role is given to statistical data validation, data cleaning based on predefined restrictions, and data cleaning strategy. Key features: -Focuses on the automation of data cleaning methods, including both theory and applications written in R.-Enables the reader to design data cleaning processes for either one-off analytical purposes or for setting up production systems that clean data on a regular basis.-Explores statistical techniques for solving issues such as incompleteness, contradictions and outliers, integration of data cleaning components and quality monitoring.-Supported by an accompanying website featuring data and R code. This book enables data scientists and statistical analysts working with data to deepen their understanding of data cleaning as well as to upgrade their practical data cleaning skills. It can also be used as material for a course in data cleaning and analyses.},
isbn = {9781118897140},
year = {2018},
title = {Statistical data cleaning with applications in R},
language = {eng},
author = {Mark {van der Loo} and Edwin {de Jonge}},
keywords = {Statistics -- Data processing; R (Computer program language)},
}

@article{plyr,
   author = {Hadley  Wickham},
   title = {The Split-Apply-Combine Strategy for Data Analysis},
   journal = {Journal of Statistical Software, Articles},
   volume = {40},
   number = {1},
   year = {2011},
   issn = {1548-7660},
   pages = {1--29},
   doi = {10.18637/jss.v040.i01},
   url = {https://www.jstatsoft.org/v040/i01}
}

@article{MurnaneRichardJ1999DMDB,
issn = {0193-841X},
abstract = {The authors use longitudinal data from the National Longitudinal Survey of Youth to investigate whether the wage trajectories of male high school dropouts are affected by the acquisition of the General Educational Development (GED) credential, by postsecondary education, and by training. The authors show that acquisition of the GED results in wage increases for dropouts who left school with weak skills, but not for dropouts who left high school with stronger skills. College and training provided by employers are associated with higher wages for male dropouts.},
journal = {Evaluation review},
pages = {475--503},
volume = {23},
publisher = {Sage Publications},
number = {5},
year = {1999},
title = {Do Male Dropouts Benefit from Obtaining a GED, Postsecondary Education, and Training?},
language = {eng},
address = {Thousand Oaks, CA},
author = {Murnane, Richard J and Willett, John B and Boudett, Kathryn Parker},
keywords = {Adolescent ; Adult ; Dropouts ; Education - economics ; Educational surveys ; Evaluation ; General educational development tests ; Health technology assessment ; Humans ; Income ; Inservice Training ; Longitudinal Studies ; Male ; Regression Analysis ; Reports ; Social aspects ; Socioeconomic Factors ; Student Dropouts - education ; United States ; Wages},
}

@article{racismnotrace,
  author = {Fullilove, M.~T.},
  title = {Comment: abandoning ``race" as a variable in public health research--an idea whose time has come},
  journal = {American Journal of Public Health},
  year = 1998,
  volume = 88,
  number = 9,
  pages = {1297-1298},
  dii= {10.2105/ajph.88.9.1297}
}

@article{tamedata,
  author = {Kim, A. Y and Ismay, C. and Chunn, J.},
  year = 2018,
  title = {The fivethirtyeight {R} Package: ``Tame Data" Principles for Introductory Statistics and Data Science Courses},
  journal = {Technology Innovations in Statistics Education},
  volume = 11,
  number = 1,
  doi = {10.5070/T511103589}
}

@article{grimshaw,
  author = {Scott D. Grimshaw},
  title = {A Framework for Infusing Authentic Data Experiences Within Statistics Courses},
  journal = {The American Statistician},
  volume = {69},
  number = {4},
  pages = {307-314},
  year  = {2015},
  publisher = {Taylor & Francis},
  doi = {10.1080/00031305.2015.1081106}
}

