---
title: "The Journey from Wild to Textbook Data: A Case Study from the National Longitudinal Survey of Youth"
authors:
  - name: Dewi Amaliah
    thanks: ""
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: dama0007@student.monash.edu
  - name: Dianne Cook
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: dicook@monash.edu
  - name: Emi Tanaka
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: emi.tanaka@monash.edu
  - name: Kate Hyde
    thanks: ""
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: ""
  - name: Nicholas Tierney
    thanks: ""
    department: ""
    affiliation: ""
    location: ""
    email: ""
bibliography: references.bib
biblio-style: unsrt
#preamble: >
header-includes:
  - \usepackage{tcolorbox}
  - \usepackage{fontawesome}
  - \usepackage{color, colortbl}
output: 
  #rticles::arxiv_article:
    #keep_tex: false
  bookdown::pdf_book:
    base_format: rticles::arxiv_article
date: "24/02/2021"
always_allow_html: true
keywords: "Data cleaning; Data tidying; Reproducible workflow; Longitudinal data; NLSY79; Initial data analysis;"
abstract: > 
 The National Longitudinal Survey of Youth (NLSY79) is a prominent open data source that has been important for educational purposes and multidisciplinary research on longitudinal data. Subsets of this data can be found in numerous textbooks and research articles. However, the steps and decisions taken to get from the raw data to the textbook data are never clearly articulated. This article describes our journey when trying to re-create a textbook example data set from the original database, with the goal being to refresh the textbook data more regularly. Thus, this paper demonstrates the process -- extracting, tidying, cleaning, and exploring with documentation -- to make refreshed data available for education or research. Three new data sets and the code to produce them are provided in an accompanying open source R package, called [CENSORED]. As a result of this process, some recommendations are also made for the NLSY79 curators for incorporating data quality checks and providing more convenient samples of the data to potential users. 
---

```{r censor, include = FALSE}
CENSOR <- TRUE
yowie <- ifelse(CENSOR, "\\texttt{[CENSORED]}", "\\texttt{yowie}")
yowie_repo <- ifelse(CENSOR, "CENSORED", "https://github.com/numbats/yowie")
yowie_pkgdown <- ifelse(CENSOR, "CENSORED", "https://github.com/numbats/yowie")
yowie_shiny <- ifelse(CENSOR, "CENSORED", "https://ebsmonash.shinyapps.io/yowie_app/")
```


```{r setup, echo = FALSE, cache = FALSE, include = FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, 
               warning = FALSE, 
               message = FALSE,
               cache = TRUE, 
               cache.path = "cache/",
               fig.retina = 2,
               fig.path = "figures/",
               comment = "#>",
               fig.align = 'center')
read_chunk(here::here("data-raw/data-preprocessing.R"))
read_chunk(here::here("data-raw/ida.R"))
read_chunk(here::here("data-raw/eda.R"))
```

```{r ref.label=c("load-pkgs", "load-pkgs2"), cache = FALSE}
```

```{r theme, eval = FALSE}
theme_set(theme_bw(base_size = 18) +
            theme(plot.background = element_rect(fill = 'transparent', colour = NA), axis.line.y = element_line(color = "black", linetype = "solid"),
                  plot.title.position = "plot",
                  plot.title = element_text(size = 24),
                  panel.background  = element_rect(fill = 'transparent', colour = NA),
                  legend.background = element_rect(fill = 'transparent', colour = NA),
                  legend.key        = element_rect(fill = 'transparent', colour = NA)
                  ) )
```


# Introduction {#intro}

"Open data" is data that is freely accessible, modifiable, and shareable by anyone for any purpose [@opendata]. This type of data can be useful as example data in statistical textbooks and for research purposes. However, open data is often referred to as what we might call "wild data" because it requires substantial cleaning and tidying to tame it into textbook shape. @HuebnerMariannePhD2016Asat emphasize that making the data cleaning process accountable and transparent is imperative and essential for the integrity of downstream statistical analyses and model building <!-- AE comment: It's unclear from context what is being referred to from the Huebner et al 2020 citation -->  [@HuebnerMarianne2020Haar]. 
Data cleaning can be considered to be a part of what is called "initial data analysis" (IDA) [@Chatfield1985TIEo]. In IDA one would also explore the data, especially to check if the data is consistent with assumptions required for modeling. This is also related to exploratory data analysis (EDA), coined by @tukey with a focus on learning from data. EDA can be considered to encompass IDA. @DasuTamraparni2003Edma say that data cleaning and exploration, without naming it as IDA, is a difficult task and consumes 80% of the data mining task. 

Despite it's importance, this IDA stage is often undervalued and neglected [@Chatfield1985TIEo]. There are few research papers that document the data cleaning [@WickhamHadley2014TD]. Furthermore, the decisions made in this stage often go unreported in the sense that IDA is often performed in an unplanned and unstructured way and is only shared among restricted parties [@HuebnerMarianne2020Haar]. 

This paper demonstrates the steps of IDA, and documents the process, for a prominent open data source, National Longitudinal Survey of Youth 1979, henceforth referred to NLSY79. This data has been playing an important role in research in various disciplines, including but not limited to economics, sociology, education, public policy, and public health for more than a quarter of the century [@MichaelRPergamit2001DWTN]. In addition, this is considered a carefully designed longitudinal survey with high retention rates, making it suitable for life course research [@MichaelRPergamit2001DWTN; @eliznlsy]. According to @eliznlsy, thousands of articles, and hundreds of book chapters and monographs have utilized this data. Moreover, the NLSY79 is considered the most widely used and most important cohort in the survey data [@MichaelRPergamit2001DWTN]. 

@SingerJudithD2003Alda used the wages and other variables of high school dropouts from the NLSY79 data as an example data set to illustrate longitudinal data modeling of wages on workforce experience, with covariates education and race. <!--AE comment: For example, I would like more discussion about the textbook selected as the exemplar. It sounds like this dataset is used in many books, why choose that one? The text should include the name of the book, so readers do not need to flip to the citations in order to learn what it was. From the name, I am guessing that the book focuses heavily on this dataset, which is why it makes sense to reproduce their subset. Be explicit about this.-->
Our aim is to refresh this textbook data with data from 1994 through to the latest data reported in 2018, a purpose that is consistent with @grimshaw's statistics education goal of embracing authentic data experiences. Here, we investigate the process of getting from the raw NLSY79 data to a textbook data set as similar as possible to that provided by @SingerJudithD2003Alda. We should also note that race is a variable in the original data set, and for compatibility it is also provided with the refreshed data, for the purposes of studying racism, not race [@racismnotrace].  <!--However, we cannot create the exact same data set as published in their book since we do not have the information of what age threshold they used to determine the high school dropouts.-->

Our process of cleaning builds heavily on the `tidyverse` approach [@tidyverse]. The data is first organised into "tidy data" [@WickhamHadley2014TD] and then further wrangled using the data pipeline and split-apply-combine approach [@plyr]. <!--AE comment: this is an important point that shouldn't be relegated to a parenthetical statement. --> (Tidy data shouldn't be confused with "tame data" which @tamedata coined to refer to textbook data sets suitable for teaching, particularly teaching statistics.) The resulting (tame) data is provided in a new R package called `yowie` which includes the code so that the process is reproducible, and could be used to further refresh the data as new records are made available in the NLSY79 database. 

This paper is structured in the following way. Section \@ref(database) describes the NLSY79 data source. Section \@ref(cleaning) presents the steps of cleaning the data, including getting and tidying the data from the NLSY79 and IDA to find and repair anomalies. Our final subset is compared to the old textbook subset in Section \@ref(compare). Finally, Section \@ref(summary) summarizes the contribution and makes recommendations for the NLSY79 data curators. 

# The NLSY79 {#database}

## Database

The NLSY79 is a longitudinal survey administered by the U.S Bureau of Labor Statistics that follows the lives of a sample of American youth born between 1957-1964 [@nlsy79]. The cohort originally included 12,686 respondents aged 14-22 when first interviewed in 1979. <!--AE comment: “It comprised of Blacks, Hispanics, economically disadvantaged non-Black non-Hispanics, and youth in the military.” Definitely needs to remove the term “Blacks” as that is considered to be offensive. Perhaps “It comprised of people sampled because they were Black, Hispanic, economically disadvantaged, or in the military.” --> It comprised of Blacks, Hispanics, economically disadvantaged non-Black non-Hispanics, and youth in the military. <!--AE comment: “1,643 members of the economically disadvantaged non-Black non-Hispanics, respectively” could perhaps be rephrased to “1,643 members who were selected because of their economic disadvantage, but were not Black or Hispanic.”-->In 1984 and 1990, two sub-samples were dropped from the interview; the dropped subjects were the 1,079 members of the military sample and 1,643 members of the economically disadvantaged non-Black non-Hispanics, respectively. Hence, 9,964 respondents remain in the eligible samples. The surveys were conducted annually from 1979 to 1994 and biennially thereafter. Data are currently available from Round 1 (1979 survey year) to Round 28 (2018 survey year).

<!--AE comment: I found the semicolons distracting. Perhaps replace them with commas and use parenthetical for sub-categories, or use a bulleted list.-->
Although the main focus area of the NLSY is labor and employment, the NLSY also covers several other topics, including education; training and achievement; household, geography, and contextual variables; dating, marriage, cohabitation; sexual activity, pregnancy, and fertility; children; income, assets and program participation; health; attitudes and expectations; and crime and substance use. 

There are two ways to conduct the interview of the NLSY79, which are face-to-face or by telephone interviews. In recent survey years, more than 90 percent of respondents were interviewed by telephone [@eliznlsy].

## Target data {#target}

<!--AE comment: What does “yearly mean hourly wages with years of workforce experience” mean? Is that one variable or two?-->
<!--AE comment: Was your goal to collect data from 1994-2018 or 1979-2018? Page 4 states 1994 onward, but from the figures later it appears that you collected data starting in 1979 (which makes more sense to me).-->
<!--AE comment: “The NLSY79 data used in Singer and Willett (2003) contains the longitudinal measurements on yearly mean hourly wages with years of workforce experience, and demographic variables education and race, from 1979 through to 1994.” Might work better split into two sentences. -->
The NLSY79 data used in @SingerJudithD2003Alda contains the longitudinal measurements on yearly mean hourly wages with years of workforce experience, and demographic variables education and race, from 1979 through to 1994. In addition, the cohort is restricted to male high-school dropouts who first participated in the study at age 14-17 years. 
<!--AE comment: Thus the target of our study is to collect the same variables for the same time period and extending through to 2018, the most recent year reported.-->Thus the target data set is to collect the same variables for the extended time frame of 1994 through to 2018, the most recent year reported.

<!-- Since no specific criteria on high school dropouts was defined
in @SingerJudithD2003Alda, we define high school dropouts as respondents who only completed either 9th to 11th grade, or who completed 12th when their age is at least 19 years old (meaning that the individual may have dropped out of high school but returned at a later time to complete high school education). XXX This should probably go further down in the flow. -->

# Data cleaning {#cleaning}

@LooMarkvander2018Sdcw describe the notion of a "statistical value chain" where the production stages of the data cleaning process are earmarked as raw data (data as arrived to the desk of an analyst), input data (data organised with correct type and identified variables) and valid data (data that faithfully represent the variables).  In this section, we outline the steps to download the raw data (Section \@ref(getdata)) and then tidy the raw data into input data, specifically for the demographic variables (Section \@ref(tidydemog)) and the employment variables (Section \@ref(tidyemp)), so that the resulting input data can be used downstream for validating the data as described in Section \@ref(ida).


## Getting the data {#getdata}


The NLSY79 data contains a large number of variables but for our aim, the scope required is limited to demographic profiles and wages data. More specifically, we went to the NLSY79 database website at \url{https://www.nlsinfo.org/content/cohorts/nlsy79/get-data}, clicked on the direct link to NSLY79 data and navigated as described in Figure \ref{fig:source-nav}.

\begin{figure}[t]

\begin{tcolorbox}[title = Navigating the data source]
\faDatabase\ NLSY79 (\url{https://www.nlsinfo.org/investigator/pages/search?s=NLSY79})\\
\vspace{1mm}
\faCheck\ The CASEID will be always be selected.  \\
\vspace{1mm}
\faCheck\ The 3 recommended demographic variable (sample ID, race and sex) were selected.  \\
\vspace{1mm}
For the remaining variables, we went to the "Variable Search" tab and select variables as follows
\begin{itemize}
\item[$\triangleright$] Education, Training and Achievement Scores
\begin{itemize}
\item[$\triangleright$] Education $\triangleright$ Summary measures $\triangleright$ All schools $\triangleright$ By year $\triangleright$ Highest grade completed
\begin{itemize}
\item[\faCheck] All 80 variables in Highest grade completed were selected.
\end{itemize}
\end{itemize}
\item[$\triangleright$] Employment
\begin{itemize}
\item[$\triangleright$] Summary measures $\triangleright$ By job
\begin{itemize}
\item[$\triangleright$] Hours worked  
\begin{itemize}
\item[\faCheck] All 442 primary variables in Hours worked were selected.
\end{itemize}
\item[$\triangleright$] Hourly wages
\begin{itemize}
\item[\faCheck] All 156 variables in Hourly wages were selected.
\end{itemize}
\end{itemize}
\end{itemize}
\item[$\triangleright$] Household, Geography and Contextual Variables
\begin{itemize}
\item[$\triangleright$] Context $\triangleright$ Summary measures $\triangleright$ Basic demographics $\triangleright$ Date of birth
\begin{itemize}
\item[\faCheck] All 4 variables in Date of birth were selected. 
\end{itemize}
\end{itemize}
\end{itemize}
\begin{itemize}
\item[\faCloudDownload] To download all 686 variables selected, we then navigate to the tab "Save / Download" then select the tab "Advanced Download". We select the R Source code and Comma-delimited datafile of selected variables with Reference Number as column headers. We name the filename "NLSY79" and press the download button. There are also options to get control or dictionary files for SAS, SPSS and STATA. 
\end{itemize}
\end{tcolorbox}
\caption{The above documents the steps taken to select variables of interest and download the raw data.\label{fig:source-nav}}
\end{figure}
      
The downloaded data set comes as a zip file, containing the following set of files:

- `NLSY79.csv`: Comma Separated Value format of the response data,
- `NLSY79.dat`: .dat format of the response data,
- `NLSY79.NLSY79`: Tagset of variables that can be uploaded to the website to recreate the data set, and
- `NLSY79.R`: R script for reading the data into R and converting the variables' names and label into something more sensible. 

We alter only the file path in `NLSY79.R` and run the script without any other alteration. This results in an initial processing of the raw data into two data sets,  `categories_qnames` (where the observations are stored in categorical/interval values) and `new_data_qnames` (the observations are stored in integer form). 

```{r raw-data}
```

The raw data, `new_data_qnames`, is organised such that each row corresponds to an individual. As respondents can have multiple jobs at specific years, the column names, such as `HRP1_1979`, `HRP2_1979`, `HRP1_1980` and `HRP2_1980`, contain the information about the job number up to 5 (`HRP1` = job 1, `HRP2` = job 2) and the year. The raw data consequently has a large number of columns (686 to be specific). The values in the cell under the variables that begin with `HRP` correspond to the hourly wage in dollars. A glimpse of this data output is shown below.

```{r untidy-data}
```

According to @WickhamHadley2014TD, tidy data sets comply with three rules: (i) each variable forms a column, (ii) each observation forms a row, and (iii) each type of observational unit forms a table. The raw data does not comply with these rules, thus we re-arrange and wrangle the data into tidy data form, columns corresponding to individual ID, year, job number, wage in dollars and the demographic variables.<!-- AE comment: This sentence is unclear. What is dplyr used for? Are there tidyverse packages used but not mentioned? If not, splitting this sentence into two may make it clearer which package is used to what purpose. Also, I haven't tried it in code, but I imagine that the data could be tidied as described just using pivot_longer, at least for the job number, year, and wage data. In other words, I don't see why dplyr or stringr would be needed for the data described on page 6.--> This is done using the `tidyverse` suite of packages [@tidyverse], `tidyr` [@tidyr] to pivot the data into long form, `dplyr` [@dplyr], and `stringr` [@stringr] for creating new variables, and levels of factors by text wrangling. The long form of the data makes it possible to do these data transformations efficiently, and it is an intermediate step towards the final target data. The code for tidying the data are demonstrated at \url{`r yowie_pkgdown`/articles/raw-to-input-data.html} but also described in the subsequent subsections.

<!-- required by making use of the `tidyverse` suite of packages [@tidyverse], which include the main set of packages needed, namely `tidyr` [@tidyr], `dplyr` [@dplyr], and `stringr` [@stringr]. The tidy data form, where we have a variable that indicates the individual ID, year, job number, wage in dollars and demographic variables, is important for downstream analysis, such as visualisation and modelling that will be performed later. 


[REMOVE] Unfortunately, the `new_data_qnames` did not meet these requirements in the way that data for each year and job for the same respondent is stored as one variable. Hence, the data contains a huge number of columns (686 columns). The example of the untidy data set is displayed in Table \ref{tab:untidy-data}. The table intended to display the hourly rate of each respondent by job (HRP1 to HRP5) and by year (1979 and 1980). The table implies that the column headers are values of the year and job, not variable names. Consequently, the data should be tidied and wrangled first to extract the demographic and employment variables we want to put in the final data set. We mainly used `tidyr` [@tidyr], `dplyr` [@dplyr], and `stringr` [@stringr] to do this job.-->

### Tidying demographic variables {#tidydemog}

In our final target data, we wish to include the demographic variables with variable names specified in brackets: gender (`gender`), race (`race`), age (`age_1979`), highest grade completed (`hgc`), highest grade completed in terms of years, e.g. 9th grade = 9, 3rd year college = 15, (`hgc_i`) and the corresponding year this grade was completed (`yr_hgc`).

For gender and race, we only rename the column names. It is worth noting that using these two variable needs special attention. Gender, as reported in the data, only has two categories, which is recognised today as inadequate. Gender is not binary. Further, race is as reported in the database. When doing analysis with this variable, one should keep in mind that the purpose is to study racism rather than race.

The `new_data_qnames` contains the variables `Q1-3_A~Y_1979` and `Q1-3_A~Y_1981` which records two versions of the birth year of the respondent; this is also the case for the record of birth month (`Q1-3_A~M_1979` and `Q1-3_A~M_1981`). The record contains two versions of birth year and birth month as the survey recorded this in 1979 and 1981. We checked for consistency between the two versions and found no discrepancy where the responses were recorded in both 1979 and 1981. The age was then calculated using the birth year. 


```{r dob-tidy}
```
```{r demog-tidy}
```
```{r demog-ed}
```

<!--AE comment: I was confused by the following section: “We choose to use this revised May data because it seemed to have less missing and presumably has been checked. However, there is no revised May data for 2012, 2014, 2016, and 2018, thus, we use the ordinary May data for these years.” I was assuming the data was collected on a yearly basis, but this section suggests it was collected each month. Please clarify somewhere in the paper. 
-->
The next step is tidying to obtain `hgc` and `yr_hgc`. The highest grade completed are recorded in `new_data_qnames` as variables beginning with `Q3-4` and `HGC` with suffix of the year it was recorded. In addition the variables beginning with `HGCREV` contain the revised data. We choose to use this revised May data because it seemed to have less missing and presumably has been checked. However, there is no revised May data for 2012, 2014, 2016, and 2018, thus, we use the ordinary May data for these years. 

```{r tidy-grade}
```

The `hgc` is measured and could be updated in each period of the survey. We chose to only retain the highest grade completed for each individual and derived the year when they completed it (`yr_hgc`) by finding the minimum year with the highest completed grade. 

```{r tidy-hgc}
```

Finally, we get all of the demographic profiles of the NLSY79 cohort. We then save this data as `demog_nlsy79`. 

```{r full-demog}
```


### Tidying employment variables {#tidyemp}

Our target variables for the employment are to obtain respondent's mean hourly wage (`mean_hourly_wage`), the number of jobs (`number_of_jobs`) and the total hours of work per week (`total_hours`) for each survey year. As the data only reports up to 5 jobs for each respondent, the maximum number of jobs is capped at 5. 

From 1979 to 1987, `new_data_qnames` only contains one version of hours worked per week for each job (in the variables with names starting with `QES-52A`). From 1988 onward, we selected the total hours worked per week, including hours working from home (`QES-52D`). However, in 1993, this variable was missing for the first and last job so we selected to use `QES-52A` instead. In addition, 2008 only had jobs 1-4 for the `QES-52D` variable, so we use only these.

```{r tidy-hours}
```

The hourly wages are in the variables beginning with `HRP` in `new_data_qnames`. As a respondent may have multiple jobs, the `mean_hourly_wage` is computed as a weighted average of the hourly wage for each job with the number of hours worked for each job as weights (provided that the information on number of hours is available); if number of hours worked for any job is missing, then the `mean_hourly_wage` is computed as a simple average of all available hourly wages. Prior to computing the mean hourly wage, we undertook a number of steps to treat unusual observations as described below:

* If the hourly rate is recorded as 0, we set wage as missing.
* If the total hours of worked for the corresponding job is greater than 84 hours, we set the wage and hour worked as missing. 

The number of jobs (`number_of_jobs`) for each respondent per year is computed from the number of non-missing values of hourly wage *and* hours worked. If either the hourly wage or hours worked is missing, we do not tally this. <!-- AE comment: "If either the hourly wage or hours worked is missing, we do not tally this." I take "this" to mean "number_of_jobs". But in row 2, total_hours is missing, yet number_of_jobs is 1. The number of jobs (1) was tallied even though hours worked was missing. -->  

```{r tidy-rate}
```

```{r tidy-nojob}
```

The employment and demographic variables are then joined. These data are further filtered to the cohort who completed education up to 12th grade and participated in at least five rounds in the survey. We save the resultant wage data on this cohort as `wages`.  

```{r wages-demog-hs}
```


## Initial data analysis {#ida}

According to @HuebnerMariannePhD2016Asat, initial data analysis (IDA) is the step of inspecting and screening the data after being collected to ensure that the data is clean, valid, and ready to be deployed in the later formal statistical analysis. Moreover, @Chatfield1985TIEo argues that the two main objectives of IDA are data description, which is to assess the structure and the quality of the data, and model formulation without any formal statistical inference. 

In this paper, we conduct an IDA or a preliminary data analysis to assess the consistency of the data with the cohort information that the NLSY provides. <!-- AE comments: This comes as a surprise to the reader. What anomaly? The wage anomalies should be mentioned in the introduction so as not to be a surprise at this point in the manuscript.
 -->In addition, we also aim to find the anomaly in the wages values using this approach. We mainly use graphical summaries to do the IDA using `ggplot2` [@ggplot2] and `brolgar` [@brolgar]. 

As stated previously, the respondents' ages ranged from 12 to 22 when first interviewed in 1979. Hence, we validate whether all of the respondents were in this range. Additionally, the [NLSY](https://www.nlsinfo.org/content/cohorts/nlsy79/intro-to-the-sample/nlsy79-sample-introduction) also provides the number of the survey cohort by their gender (6,403 males and 6,283 females) and race (7,510 Non-Black/Non-Hispanic; 3,174 Black; 2,002 Hispanic). To validate this, we used the `demog_nlsy79`, i.e., the data with the survey years 1979 sample. <!--AE comment:  I don't know that Table 1 is necessary as I don't have anything to compare it to. If the numbers check out, a simple statement to that effect would suffice. Also, what does "(?CHECK)" mean? This needs to be resolved.--> 
<!--AE comment: Table 1 includes the note ?CHECK which I assume was a note to self. -->
Tables \ref{tab:age-table} and \ref{tab:gender-race-table} suggest that the demographic data we had is consistent with the sample information in the database.


```{r age-table}
```

<!--AE comment: Table 2 seems to have more precision than is necessary. Certainly 100% does not need to be reported as 100.00%, and probably all the percentages could be rounded to the nearest 1 percent. The caption could explain this, as there might be some rounding errors. -->

```{r gender-race-table}
```

In the next step, we explore the mean hourly wage data. In this case, we only explore the wages data of respondents that have the highest completed grade of up to $12^{th}$ grade.  We employ visualization techniques to perform the IDA as described next.

```{r summarytable, eval=FALSE}
```

<!--AE comment: Figure 2’s caption should include something about how that data is the raw values from the survey, before inputing anomalous values so the figure and caption can stand alone.-->

```{r sample-plot, echo = FALSE, fig.cap="Longitudinal profiles of wages for a random sample of 20 individuals in the refreshed data. Most, but not all, individuals here experienced increasing wages over time, and several have experienced considerable fluctuation in wages. Some individuals are only measured for a short period.", fig.height=8, fig.width=10, out.width="100%"}
```

<!--AE comment: With the IDA about wage data, I would appreciate a bit more context. Why sample 36 observations? I am not a longitudinal data expert, so I was a bit surprised when I flipped to the plot and found it to be small-multiple time series, although upon further consideration it makes sense. In that section it would be good to describe what the figure shows in a bit more detail. Perhaps “We randomly sample 36 respondents from the data, and plot their average wage as a time series. Looking at the patterns over time, we see a lot of variability in wages. For example, the people shown in panels 5, 7, and 11 have [explain what is interesting here, again I’m not an expert].” The next sentence here, “Some have had flat wages for years but had a sudden increase in one particular year, then it gone down again, while the others experienced an upsurge in their wage, for instance, the IDs in panel 9.” does not seem to provide much additional information. What were you looking for here? Overall trends over time, increasing/decreasing? Any places where one year’s wage looked really different?-->


We randomly take 20 samples from the data and plot them, as shown in Figure \ref{fig:sample-plot}.<!--AE comment: "It" implies... Please specify what "it" refers to. This could be done by adding onto the first sentence... "as shown in Figure 2, which shows that some respondents have high variability in wages, particularly 5, 7, and 11." However, 7 and 11 don't seem to have particularly high variability, especially when compared to 18. This whole paragraph needs to be fixed/updated.--> It shows that these respondents have a lot of variability in wages, for example, the IDs in panel numbers 5, 7, and 11. The plot also implies that the samples have a different pattern of mean hourly wages. Some have had flat wages for years but had a sudden increase in one particular year, then it gone down again, while the others experienced an upsurge in their wage, for instance, <!--AE comment: Not panel 9 --> the IDs in panel 9. 
<!--I think there is a narrative step missing here, which is that looking at those samples led you to look at plots that show values for the wage variable over all participants and all years. The phrase “the summary plots” was not enough description for me to know what to expect when I flipped to Figure 3. Please be explicit about what the three plots were, why they were made, and what you were looking for. I think there is another narrative step missing about Figure 3C, which is that after you saw there were outliers you tried to identify which respondents had the extreme values. Again, please spell this out in the text. When you return to the plots for the entire dataset in Figure 5, please make parallel comments. -->However, when checking the summary plots (Figure \ref{fig:feature-plot}), we found that some observations had exceptionally high wages. Some of them, for example respondents in Figure \ref {fig:feature-plot} C had experienced unusual wages only in certain year. 


<!--For both Figure 3 and Figure 5, I would prefer the letter label before the description, but that’s a matter of personal preference.-->

```{r feature-plot, fig.cap = "Summary plots to check the cleaned data reveal more cleaning is necessary: longitudinal profiles of wages for all individuals 1979-2018 (A), boxplots of minimum, median, and maximum wages of each individual (B), and one individual (id=39) with an unusual wage relative to their years of data (C). Some values of hourly wages are unbelievable, and some individuals have extemely unusual wages in some years.", fig.width=10, fig.height=4, out.width="100%", cache = FALSE}
```

```{r high-wages}
```

```{r high-wages, fig.cap= "6 out of 45 IDs with extremely high mean hourly wage. Most of the IDs only have one point of high wage.", eval=FALSE}
```

<!--The next paragraph, which begins “The anomalies are also found” should perhaps be “Similar anomalies were found.” Was it the same respondents with the extremely high wages that showed extremely high number of hours of work? I suspect not, but please be explicit.-->
<!--AE comment: Rewrite this sentence. "Observations" aren't working 420 hours. A "respondent" might have been reported as having worked 420 hours per week.--> The anomalies are also found in the total hours of work, where some observations reported as having worked for 420 hours a week in total. 
According to @MichaelRPergamit2001DWTN, one of the flaws of the NLSY79 employment data is that the NLSY79 collects the information of the working hours since the last interview. Thus, it might be challenging for the respondents to track the within-job hours' changes between survey years, especially for the respondents with fluctuating working hours or seasonal jobs. It even has been more challenging since 1994, where the respondents had to recall two year periods. This shortcoming might also contribute to the fluctuation of one's wages data. 


### Replacing extreme values {#censor}

<!--AE comment: Section 3.2.1 begins “As part of the IDA, which is the model formulation, we build a robust linear regression model to treat the extreme values in the data.” This could use clarification. In 3.2, you said that part of IDA is “ model formulation without any formal statistical inference.” To me, that sounds like using modeling as a descriptive technique, and it’s something I would consider to be more a part of EDA. But then in 3.2.1, while it is perhaps not using modeling in an inferential way, the model is being used for more than just description. I might rephrase the first sentence as follows: “In order to treat the extreme values in the data, we built a robust linear regression model.” -->
As part of the IDA, <!--AE comment: Awkward sentence. "which is the model formulation"?--> which is the model formulation, we build a robust linear regression model to treat the extreme values in the data. Robust linear regression yields an estimation robust to the influence of noise or contamination [@KollerManuel2016rARP]. It also aims to detect the contamination by weighting each observation based on how "well-behaved" they are, known as robustness weight. Observations with lower robustness weight are suggested as an outlier by this method [@KollerManuel2016rARP]. 

Since we work with longitudinal data, we build the model for each ID instead of the overall data. The robust mixed model could be the best model to be employed in this case. However, this method is too computationally and memory expensive, especially for a large data set, like the NLSY79 data. <!--I would pull the tidy and purrr citations to the end of the sentence to make it read more smoothly-->Therefore, the model for each ID is built utilizing the `nest` and `map` function from `tidyr` [@tidyr] and `purrr` [@purrr], respectively. The full code for this is shown at \url{`r yowie_pkgdown`/articles/input-to-valid-data.html} but also described in detail next.

We build the model using the `rlm` function from `MASS` package [@mass]. We set the `mean_hourly_wage` and `year` as the dependent and predictor, respectively. Furthermore, we use M-Estimation with Huber weighting, where the observation with a slight residual gets a weight of 1, while the larger the residual, the smaller the weight (less than 1) [@rlm]. <!--AE comment: “However, the challenging part of detecting the anomaly using the robustness weight is determining the weight threshold in which the observations are considered outliers.” I don’t think this sentence needs a “However” and probably should say “past which” rather than “in which”-->However, the challenging part of detecting the anomaly using the robustness weight is determining the weight threshold in which the observations are considered outliers. Moreover, it should be noted that not all the outliers are due to an error. Instead, it might be that one had reasonably increasing or decreasing wages in a particular period. 

<!--AE comment: At the bottom of page 11, where you describe the model formation, more detail would be appreciated. You are modeling the mean hourly wage based on year. Why? Is this standard practice for robust linear regression? What is a “slight” residual? Is it defined based on absolute magnitude, or standard deviations, or something else? Later, you say “To minimize the risk of mistakenly identifying an outlier as an “erroneous outlier”.” Is an erroneous outlier a technical term? If not, I think you are trying not to identify erroneous outliers, not mistakenly identifying outliers as erroneous outliers (that’s a double negative). The value of 0.12 feels very specific and out of place in a paper that has had few numerals. Is this a number an expert in RLR would be able to understand? Again, is that a raw value? Is it a standard deviation? Is there literature about how to choose a threshold? Overall, the sentence “We find that 0.12 is the most reasonable value to be the threshold to minimize that drawback’s risk because it still captures the sensible spikes in the data.” is vague and should be expanded upon. What is “that drawback’s risk”? What are “the sensible spikes in the data?” Be more explicit.-->

To minimize the risk of mistakenly identifying an outlier as an "erroneous outlier", we simulate some thresholds and study how they affect the data. We find that 0.12 is the most reasonable value to be the threshold to minimize that drawback's risk because it still captures the sensible spikes in the data. In other words, we keep maintaining the natural variability of the wages while minimizing anomalies because of the error in the data recording. After deciding the threshold, we impute the observations whose weights are less than 0.12 with the models' predicted value. We then flag those observations in a new variable called `is_pred`. 


```{r rlm, eval=FALSE}
```

Figure \ref{fig:compare-plot} shows the mean hourly wage before and after the extreme values are replaced. It implies that the fluctuation can still be observed in the data after the treatment. However, the large spikes, which are considered "erroneous outliers", are already eliminated from the data. Hence, the model produces a data set with a more reasonable degree of fluctuation.


```{r compare-data}
```


```{r compare-plot, fig.cap="Comparison between the original (black dots) and the corrected (solid grey) mean hourly wage for a sample of individuals. A robust linear model prediction was used to correct mean hourly wages value. We can see that some extreme spikes, corresponding to implausible wages, have been replaced with values more similar to wages in neighboring years, but otherwise the profiles are not changed. Some spikes might remain when wage vaues are plausible.", fig.height=8, fig.width=10, out.width="90%"}
```

Further, Figure \ref{fig:fixed-feature-plot} A shows that after eliminating the extreme values, the highest value has decreased to be around $350. The spikes are still observed but not as extreme as the original data set. In Figure \ref{fig:fixed-feature-plot} B, we plot the three features of mean hourly wages, namely the minimum, median, and maximum value. 
<!--AE comment: What does “It implies that the fluctuation can still be observed in the data after the treatment.” mean? I suspect this sentence should be replaced with something along the lines of “The figure shows that fluctuations in wages still exist even in the imputed data.”-->
We still can see some extreme values in maximum wages, but consider it as a natural variability of the data. In Figure \ref{fig:fixed-feature-plot} C, we can see that after imputing the extreme value in ID=39, we can see how the the wages change over the years more clearly. 


```{r fixed-feature-plot, fig.cap = "Re-make of the summary plots of the fully processed data suggest that it is now in a reasonable state: longitudinal profiles of wages for all individuals 1979-2018 (A), boxplots of minimum, median, and maximum wages of each individual (B), and one individual with an unusual wage relative to their years of data (C). ", fig.width=10, fig.height=4, out.width="100%", cache = FALSE}
```


Finally, we save the imputed data and set the appropriate data type for the variables.

```{r save-data}
```

```{r nrow}
```


## Recap 

Figure \ref{fig:flow-chart-blind} summarizes the steps taken to go from raw to input to valid data [@LooMarkvander2018Sdcw] to create a refreshed wages data set. 

<!--To summarise, the  a workflow from getting the data from the NSLY79 database until a ready-analysed data. Referring to @LooMarkvander2018Sdcw, this section shows  part of statistical value chain, which is data cleaning from raw, input, and valid data. The raw demographic and employment data from the database are not in a tidy format. Hence, we perform data wrangling to get the input data. We inspect the input data to find eligible observations to the target data. One of the target data is wages data of respondents who completed up to 12th grade and participated at least in 5 rounds of survey. This needs us to join the extracted demographic and employment data. 

Further, using IDA, we inspect on the existence of anomalies/extreme values in the data using the weight from robust linear model. We then replace these extreme values using their predicted value. 
From this stage forward, we assume that we already have valid data. We also subset the data to get the wages of high school dropouts. We then make these three data sets and the cleaning workflow documentation publicly available through an R data container package called `yowie`. A visualisation of these process is displayed in  Figure \ref{fig:flow-chart}.-->

(ref:flow-chart) The stages of data cleaning from the raw data to get three datasets contained in `r yowie`. "# of individuals" means the number of respondents included in each stage, while "# of observations" means the number of rows in the data. The color represents the stage of data cleaning in statistical value chain [@validate]. Pink, blue, and green represent the raw, input, and valid data, respectively.

```{r flow-chart-blind, fig.cap="(ref:flow-chart)", out.width="85%", eval = CENSOR}
```

```{r flow-chart, fig.cap="(ref:flow-chart)", out.width="85%", eval = !CENSOR}
```

# Comparison of refreshed with the original data {#compare}

```{r sw_wages}
```

```{r do_refreshed}
```

```{r compare-sw-do}
```

<!--AE comment: first sentence can be removed or rephrased. Next sentence includes the word wages too many times. Next sentence should say “dropouts” rather than “drop outs” to be consistent with the previous sentence. -->
Now is the time to see how close we have come to the original textbook data. The original set contains wages of high school dropouts [@SingerJudithD2003Alda] from 1979 through to 1994. The refreshed data set for comparison is also wages on high school drop outs from 1979 to 2018. The original set is available in the R package `brolgar` and the refreshed data is available in the R package `r yowie`. 

<!--AE comment: what does the natural log have to do with the y-axis?-->
<!--AE comment: For Figure 7, why did you choose to show the entire dataset here? It would be easier to make a comparison if the plot was cut off at 1994 on the x-axis.-->

```{r plotting-sw-do, fig.cap = "Comparison of original textbook example (A) with refreshed data (B). The original data was inflation-adjusted to 1990 prices and the individual's time of collection was converted to a length of experience in the workforce, which makes it difficult to precisely compare the two sets.", fig.width = 9, fig.height = 5, out.width = "100%", cache = FALSE}
```

<!--AE comment: In Section 4, you talk about the variables in the original data. “One would expect that there is a record of the day the individual first started a job, and this is used to adjust the year of collection.” I’m not sure what this means. Please clarify.-->
<!--AE comment: “experience in the workforce” should have the period inside the quotations.-->
There are two aspects of the original data that make a direct comparison difficult. The time variable provided is "experience in the workforce". It is not clear how this is calculated. One would expect that there is a record of the day the individual first started a job, and this is used to adjust the year of collection. We have not been able to find this information in the database. Secondly, wages were inflation-adjusted to 1990 prices, which is not done for the refreshed data.  

<!--AE comment: “The treatment of unlikely wages differ in the refreshed data.” I think this means “The treatment of anomalous wages differs between the original and refreshed data sets.” Then you say “We opted to use the weights from a robust linear regression to determine what should be set as missing value as described in Section 3.2.1.” I don’t think you were setting missing values though, were you? It was used to determine which values should be imputed, correct? Either way, please clarify.-->
The treatment of unlikely wages differ in the refreshed data. In the original data by @SingerJudithD2003Alda, wages greater than $75 are set to be missing. However, in recent context, this value is too low to be set as the maximum threshold. We opted to use the weights from a robust linear regression to determine what should be set as missing value as described in Section \@ref(censor).

Figure \ref{fig:plotting-sw-do} shows a comparison of the two sets. (A direct ID matching is not possible.) There are 888 individuals in the original and 1,188 individuals in the refreshed data. This suggests some individuals were removed in the original data.
In addition, in the original set the racial breakdown was 246 Black, 204 Hispanic and 438 White participants, while in the refreshed data there are 346 Black, 219 Hispanic, and 623 White participants, so the proportions have not been exactly reproduced. On education, in the refreshed data there are very few individuals with less than a 12th grade education, which is different from the original. <!--AE comment: How many individuals up to 8th grade are in the refreshed dataset? What are plausible reasons for these differences?--> In the original data there were 366 individuals with up to 8th grade and 522 9th-12th grade, as compared to 967 with 12th grade in the refreshed data. 

```{r summaries, eval=FALSE}
```

<!-- Hence, in this section, we will compare how close the `wages_hs_do`, henceforth refreshed data, to the textbook data. It is also worth noting that the textbook data is reused from @MurnaneRichardJ1999DMDB’s paper. Hence, it is not directly extracted from the NLSY79 database.  @SingerJudithD2003Alda do not state the time frame covered by the data. However, from @MurnaneRichardJ1999DMDB’s paper, we find that the textbook data cover the survey period from 1979-1994. Hence, for comparison purposes, we filter the refreshed data only until 1994. 

In the absence of highs chool dropouts criteria in the textbook data, we create a clearer criteria of high school dropouts as mentioned in Section \@ref(#target). Consequently, we do not have the same ID of high-school dropouts as in the textbook data. The textbook data has `r nrow(sw_id)` IDs included, while the refreshed data has `r nrow(do_id)` IDs. Furthermore, there are only `r nrow(sw_do)` IDs included both in the textbook and the refreshed data. After observing @MurnaneRichardJ1999DMDB’s paper, it is mentioned that the data is randomly drawn from the low income subsample of the NLSY. This is probably the reason why, even using some criteria, we cannot match the dropouts in the textbook and the refreshed data.

Further, the temporal variable used in the textbook data is experience, instead of year. The only explanation we found regarding this variable is that it is derived from the years of IDs’ experience since their first job. @SingerJudithD2003Alda stated that this variable reflects the specific moment in each ID labor force history associated with each wage observation. 
Since it is not clearly articulated, we decide to keep the temporal variable in the refreshed data as year. Accordingly, in this comparison, we only compare the same ID but not the same temporal variable. 

Regarding the wages, the textbook data express the wages as inflation adjusted with 1990 dollars as constant [@SingerJudithD2003Alda]. However, it is not stated how exactly the wages are adjusted. Note that in the refreshed data we publish in `yowie`, we do not adjust the data with inflation because the time frame covered ranged from 1979-2018. Hence, we allow flexibility to the data user to adjust, not adjust,  or adjust it with different base years. For comparison purposes, we adjust the wages with the average Consumer Price Index For All Urban Consumers (CPI-U) we got from @fed. -->



<!-- Figure \ref{fig:plotting-sw-do} shows the comparison between the textbook and the refreshed data. Even though it has different temporal variables and possibly different CPI indicators used in inflation adjustment, we can still capture some of the patterns in the refreshed data.

From this comparison, we learn that we cannot make an apple to apple comparison and produce the exact same data as the textbook due to the absence of clearly articulated data extraction and derivation process. Hence, the takeaway is that it is imperative to disclose how the data derived from the initial source to make data analysis reproducible. This is why in this paper, we show the practice of reproducible and responsible data cleaning workflow to make sure the longitudinal data from a continuous survey can be refreshed.-->


# Summary {#summary}

This paper has described the stages to take a particular open data set and make it a textbook data set, ready for the classroom or research. In the first stage, we showed the steps performed to get the data from the NLSY79 database. The data format needed conversion to tidy format, and this was described. After that, an initial data analysis was conducted to investigate and screen the quality of the data. We found and fixed the anomalous observations in wages using a robust linear regression model. Finally a comparison is made between the original and refreshed data sets.

The data cleaning process is documented and the code has been made available. These provide the opportunity to again refresh the textbook data as updated data is published in the NLSY79 database.
Determining the appropriate robustness weight to threshold the anomalous observations is documented, and a `shiny`  [@shiny] app is provided to assist. 
The current subset is made available in a new R package, called `r yowie`.

<!--AE comment: The bulleted difficulties in Section 5 are a bit jarring. Make them parallel (i.e. every bullet should start with a verb -ing so it is determining, calculating, etc) or turn them into a paragraph. I liked the specificity of $30,000/hour but it would be better up in the section where you discuss the anomalous values.-->

Various difficulties were encountered in trying to refresh the data, which include: 

- determining which records should be downloaded from the database.
- there are many errors in the data, e.g. hourly wages greater than $30,000 per hour.
- there is no explicit variable in the database recording high school dropout, which means we needed to compare date of 12th grade with the individual's age.
- calculating experience in the workforce would require knowing the time of first job within the first year the individual was recorded. 

Ultimately, the refreshed data is reasonably similar to the original, but unsatisfactorily far from it. The last step required would be to inflation-adjust wages, but this is better to do with each wave of new data added, so that it is relative to the last date in the data. 

<!--AE comment: At the end of page 14, it would be good to explicitly say that if people don’t like your decisions, they can grab the code and adjust the parameters themselves! It’s implied, but should be made explicit. -->
Some readers may disagree with our decisions made to produce the refreshed textbook data and may have better insight than us in producing a more appropriate textbook data. We do not assert that we have produced the best textbook data, but rather we describe our journey to provide a reasonable textbook data set. All code and documentation are provided for transparency, and future updates of the `r yowie` package may contain additional variables, or filters of the full set, if it is deemed important. 

Finally, for the data providers we recommend that a validation system with clear rules is added on data entry, and that alternative output formats, such as a tidy format would help users make better use of the resource. The problem with many of the wages records is that there are implausible values, or confusion on how to record wages for multiple jobs. These values can be validated with simple checks at data entry. Providing an open data resource also is accompanied with the responsibility that the data, especially data that is as valuable as this, is reliable. Users need to be able to trust the data. 

<!--this paper implies that data providers should design a database that is able to produce tidy data sets. A data provider should also check for data anomalies before the data publishing or at least provides a set of rules or threshold values. For example, in this case, is the threshold of reasonable wages. This will greatly support the data users to validate and set the same understanding of which data are considered outliers. Moreover, providing validation rules would facilitate any established data validation tool, such as `validate` [@validate] package. In this case, we cannot use this handy validation package due to the absence of validation rules. -->


# Acknowledgements 

We would like to thank Aarathy Babu for the insight and discussion during the writing of this paper. 

The entire analysis is conducted using `R` [@R] in RStudio IDE using these packages: `tidyverse` [@tidyverse], `ggplot2` [@ggplot2], `dplyr` [@dplyr], `readr` [@readr], `tidyr` [@tidyr], `stringr` [@stringr], `purrr` [@purrr], `brolgar` [@brolgar], `patchwork` [@patchwork], `kableExtra` [@kableExtra], `MASS` [@mass], `janitor` [@janitor], and `tsibble` [@tsibble]. The paper was generated using `knitr` [@knitr] and `rmarkdown` [@rmarkdown]. 


# Supplementary Materials 


- **Codes**: R script to reproduce data tidying and cleaning is available in this [page](`r yowie_pkgdown`/articles/process-data.html).

- **R Package**:`r yowie` is a data container R package that contains 3 datasets, namely the high school mean hourly wage data, high school dropouts mean hourly wage data, and demographic data of the NLSY79 cohort. This package can be accessed [here](`r yowie_repo`).

- **shiny app**: An interactive `shiny` web app to visualise the effect of selecting different weight threshold for substituting the wages data to its predicted value from a fit of the robust linear regression model. This app can be accessed [here](`r yowie_shiny`) with the source code provided [here](`r yowie_repo`/tree/master/app).


# Data Availability Statement

The authors confirm that the data supporting the findings of this study are available within the supplementary materials.

# References
